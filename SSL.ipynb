{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Self supervised learning part of the project",
   "id": "d2fa52a384b3d124"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cat\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "#Define the network\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, classes=500):    #Classes = to number of permutations\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module('conv1_s1',nn.Conv2d(3, 16, kernel_size=5))\n",
    "        self.conv.add_module('relu1_s1',nn.ReLU(inplace=True))\n",
    "        self.conv.add_module('pool1_s1',nn.MaxPool2d(kernel_size=6, stride=2))\n",
    "        \n",
    "\n",
    "        self.conv.add_module('conv2_s1',nn.Conv2d(16, 32, kernel_size=5))\n",
    "        self.conv.add_module('relu2_s1',nn.ReLU(inplace=True))\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv.add_module('conv3_s1',nn.Conv2d(32, 64, kernel_size=3))\n",
    "        self.conv.add_module('relu3_s1',nn.ReLU(inplace=True))\n",
    "        self.conv.add_module('pool3_s1',nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.conv.add_module('conv4_s1',nn.Conv2d(64, 128, kernel_size=3))\n",
    "        self.conv.add_module('relu4_s1',nn.ReLU(inplace=True))\n",
    "        self.conv.add_module('pool4_s1',nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.conv.add_module('conv5_s1',nn.Conv2d(128, 56, kernel_size=3))\n",
    "        self.conv.add_module('relu5_s1',nn.ReLU(inplace=True))\n",
    "        \n",
    "\n",
    "        self.fc6 = nn.Sequential()\n",
    "        self.fc6.add_module('fc6_s1',nn.Linear(56*3*3, 200))\n",
    "        self.fc6.add_module('relu6_s1',nn.ReLU(inplace=True))\n",
    "        self.fc6.add_module('drop6_s1',nn.Dropout(p=0.5))\n",
    "\n",
    "        self.fc7 = nn.Sequential()\n",
    "        self.fc7.add_module('fc7',nn.Linear(9*200,1400))\n",
    "        self.fc7.add_module('relu7',nn.ReLU(inplace=True))\n",
    "        self.fc7.add_module('drop7',nn.Dropout(p=0.5))\n",
    "\n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('fc8',nn.Linear(1400, classes))\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x):   \n",
    "        B,T,C,H,W = x.size()\n",
    "        x = x.transpose(0,1)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(9):  #9 patches go through the convolutional layers\n",
    "            z = self.conv(x[i])\n",
    "            z = self.fc6(z.view(B,-1))\n",
    "            z = z.view([B,1,-1])\n",
    "            x_list.append(z)\n",
    "\n",
    "        x = cat(x_list,1)   #concatenate the 9 results from the convolutional layer for the fully connected part\n",
    "        x = self.fc7(x.view(B,-1))  \n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    "
   ],
   "id": "ac4b7d6c3e0a2ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "#summary of the model\n",
    "model = Network(500)\n",
    "summary(model, (9,3, 75, 75))"
   ],
   "id": "f99e099d5b489bc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps:0\") if torch.backends.mps.is_available() else torch.device(\"cpu\")    # Check if GPU is available\n",
    "print(\"Device:\", device)    # Print the device"
   ],
   "id": "236a472d1d1ff509",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os, sys, numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from JigsawImageLoader import DataLoader    #Use the Dataloader from the original paper\n",
    "\n",
    "classes = 500   #Number of permutations\n",
    "batch_size = 68\n",
    "\n",
    "    \n",
    "#Define sets and dataloaders   \n",
    "train_data = DataLoader(\"/Users/stefanocarotti/Supervised/Project/train_set\",\"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\" ,\n",
    "                            classes= classes)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,num_workers=4)\n",
    "    \n",
    "    \n",
    "val_data = DataLoader(\"/Users/stefanocarotti/Supervised/Project/val_set\",\"/Users/stefanocarotti/Supervised/Project/annot/val_info.csv\" ,\n",
    "                            classes=classes)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=4)\n",
    "\n",
    "\n",
    "# Network initialization\n",
    "net = Network(classes=classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   # Define the loss function \n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.0002)  # Define the optimizer\n",
    "     "
   ],
   "id": "9d0cb6b4499d577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "    ############## TRAINING ###############\n",
    "print(('Start training: lr %f, batch size %d, classes %d'%(0.0002,batch_size,classes)))\n",
    "\n",
    "    \n",
    "    # Train the Model\n",
    "epochs = 50\n",
    "#Initialize loss for plotting\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "     prog_bar = tqdm( train_loader, total=len(train_loader))    \n",
    "     for i, (images, labels, original) in enumerate(prog_bar):\n",
    "        # Convert torch tensors to Variables and pass them to the GPU \n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = float(loss.cpu().data.numpy())\n",
    "        train_losses.append(loss)   #Save the loss for plotting\n",
    "        \n",
    "       \n",
    "     avg_loss = np.mean(train_losses)   #Calculate the average loss for the epoch\n",
    "    \n",
    "     print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "     net.eval()\n",
    "     correct = 0\n",
    "     total = 0\n",
    "     prog_bar = tqdm(val_loader, total=len(val_loader))\n",
    "     for i, (images, labels, original) in enumerate(prog_bar):\n",
    "        # Convert torch tensors to Variables and pass them to the GPU \n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)   #Get the predicted label\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "     accuracy = 100 * correct / total\n",
    "     print(f\"Validation Accuracy: {accuracy}%\")\n",
    "    \n",
    "        "
   ],
   "id": "de30c21398ff519a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Save the model\n",
    "torch.save(net.state_dict(), 'convnet.pth')"
   ],
   "id": "c643f17c5b15bdd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Load the model\n",
    "net = Network(classes=500).to(device)\n",
    "net.load_state_dict(torch.load('convnet.pth'))"
   ],
   "id": "951834e4cffb6eae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(train_losses)",
   "id": "d45e4a28e7c05479",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def accuracy(prediction, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((prediction == y).sum() / len(y)).item()\n",
    "\n",
    "def evaluate(model, testloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    prog_bar = tqdm( testloader, total=len(testloader)) \n",
    "    for i, (images, labels, original) in enumerate(prog_bar):  # Iterate over the validation data loader\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)  \n",
    "            labels = labels.to(device)\n",
    "            prediction = model.forward(images)\n",
    "            epoch_loss += criterion(prediction, labels)\n",
    "            epoch_acc += accuracy(torch.argmax(prediction, dim=1), labels)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(torch.argmax(prediction, dim=1).cpu().numpy())\n",
    "            \n",
    "    epoch_loss /= len(testloader)  # Calculate the average loss for the epoch\n",
    "    epoch_acc /= len(testloader)  # Calculate the average accuracy for the epoch        \n",
    "    return y_true, y_pred, epoch_loss, epoch_acc "
   ],
   "id": "a9273a45f785312f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_true, y_pred, test_loss, test_acc = evaluate(net, val_loader)",
   "id": "e852d7590acc3231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(test_acc)",
   "id": "e45bff6f1814fce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#extract the first image from the training set in order to plot Jigsaw puzzle solving in the report\n",
    "images, labels, original = next(iter(train_loader))\n"
   ],
   "id": "37822d6966baca61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#visualize the first image\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    #No axes\n",
    "    plt.axis('off')\n",
    "    #No grid\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[2][i].cpu().numpy().transpose(1,2,0))\n",
    "    \n",
    "#Save the shuffled image\n",
    "plt.savefig('shuffled_image.png')\n",
    "    \n"
   ],
   "id": "941c9a7cb6662a87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Feed the image to the network in order to recognize the permutation\n",
    "#Pass the image to device\n",
    "images = images.to(device)\n",
    "output = net(images[2].unsqueeze(0))\n",
    "output = nn.Softmax(dim=1)(output)\n",
    "print(torch.argmax(output, dim=1))  #Print the prediction\n",
    "\n",
    "#Print the label of the image\n",
    "print(labels[2])\n",
    "\n",
    "perm = np.load('permutations_500.npy')\n",
    "print(perm[144])  #Print the recognized permutation\n",
    "\n",
    "#Visualize the first image ordering the permutation\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    #No axes\n",
    "    plt.axis('off')\n",
    "    #No grid\n",
    "    plt.grid(False)\n",
    "    \n",
    "    \n",
    "    #sort the indexes of perm[i] according to the permutation\n",
    "    idx = np.argsort(perm[144])\n",
    "    plt.imshow(images[2][idx[i]].cpu().numpy().transpose(1,2,0))\n",
    "    \n",
    "#Save the unshuffled image\n",
    "plt.savefig('unshuffled_image.png')"
   ],
   "id": "3bd1062203fd86a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Use Fooddataset class from the Supervised part for the linear classifier\n",
    "\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, filelist, transform, split):\n",
    "       \n",
    "        self.split = split\n",
    "        self.root_dir = root_dir  # Set the root directory for the dataset\n",
    "        self.data = pd.read_csv(filelist, sep=\",\")  # Load the dataset         \n",
    "\n",
    "        self.transform = transform\n",
    "        total_data_len = int(len(self.data))\n",
    "        idx = np.arange(total_data_len)\n",
    "        np.random.seed(41)\n",
    "        np.random.shuffle(idx)\n",
    "        print(f\"Shuffled indices (first 5): {idx[:5]}\")  # Print first 5 shuffled indices\n",
    "\n",
    "        # Select data based on split\n",
    "        if split == \"train\":\n",
    "            self.data = self.data.iloc[idx[:int(total_data_len * 0.8)]]  # Use 80% of the data for training\n",
    "        elif split == \"val\":\n",
    "            self.data = self.data.iloc[idx[int(total_data_len * 0.8):]]  # Use 20% of the data for validation\n",
    "        else:\n",
    "            self.data = self.data  # Use all data for testing (only for code clarity)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        img_name, label = self.data.iloc[idx]  # Get the image name and label at the specified index\n",
    "        image = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        image = self.transform(image)\n",
    "\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample, img_name\n",
    "\n",
    "\n",
    "#Same transform and setting as the Supervised part\n",
    "\n",
    "# Define data transformations (augmentations for training and normalization)\n",
    "transform_train = transforms.Compose([  # Compose multiple transformations together\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally for training augmentation\n",
    "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
    "    transforms.Normalize(  # Normalize pixel values\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 (consistent with training)\n",
    "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
    "    transforms.Normalize(  # Normalize pixel values\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Set batch size\n",
    "bs = 64\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "\n",
    "trainset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/train_set\",\n",
    "                       \"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\", transform_train, \"train\")\n",
    "\n",
    "valset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/train_set\",\n",
    "                     \"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\", transform_val, \"val\")\n",
    "\n",
    "testset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/val_set\",\n",
    "                      \"/Users/stefanocarotti/Supervised/Project/annot/val_info.csv\", transform_val, \"test\")\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Print dataset length\n",
    "print(f\"Number of training samples: {len(trainloader) * bs}\")\n",
    "print(f\"Number of validation samples: {len(valloader)}\")\n",
    "print(f\"Number of test samples: {len(testloader)}\")\n",
    "\n",
    "# visualize one example\n",
    "sample, name = trainset[0]\n",
    "print(sample['image'].shape)\n",
    "plt.imshow(sample['image'].permute(1, 2, 0))\n",
    "print(name, sample['label'])\n"
   ],
   "id": "8a341a46ba2d37ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Evaluation functions from the Supervised part\n",
    "def accuracy(prediction, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((prediction == y).sum() / len(y)).item()\n",
    "\n",
    "\n",
    "def evaluate_classifier(classif_model, testloader):\n",
    "    classif_model.eval()  # Set the model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    prog_bar = tqdm(testloader, total=len(testloader))\n",
    "    for i, (sample, _) in enumerate(prog_bar):  # Iterate over the validation data loader\n",
    "        with torch.no_grad():\n",
    "            image = sample['image'].to(device)\n",
    "            label = sample['label'].to(device)\n",
    "            z = net.conv(image)  # Forward pass through the convolutional layers\n",
    "            z = torch.flatten(z, 1)  # Flatten the output from the convolutional layers\n",
    "            prediction = classif_model(z)\n",
    "            epoch_loss += criterion(prediction, label)\n",
    "            epoch_acc += accuracy(torch.argmax(prediction, dim=1), label)\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(torch.argmax(prediction, dim=1).cpu().numpy())\n",
    "\n",
    "    epoch_loss /= len(testloader)  # Calculate the average loss for the epoch\n",
    "    epoch_acc /= len(testloader)  # Calculate the average accuracy for the epoch        \n",
    "    return y_true, y_pred, epoch_loss, epoch_acc\n",
    "\n",
    "\n"
   ],
   "id": "a2f30c2d878fbbdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Linear classifier for SSL\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "sample, name = trainset[0]\n",
    "image = sample['image'].to(device)  # Pass the image to the device in order to retrieve dimensions\n",
    "\n",
    "# Retrieve the dimensions of the output from the convolutional layers\n",
    "output = net.conv(image)\n",
    "print(output.shape)\n",
    "n_classes = 251 #Food recognition task\n",
    "latent_dim = output.shape[0] * output.shape[1] * output.shape[2]\n",
    "print(latent_dim)\n",
    "def construct_classifier(latent_dim, n_classes):\n",
    "        classifier = nn.Sequential( # Define the linear classifier with dropout\n",
    "            nn.Linear(latent_dim, 1024),  # Linear layer (latent_dim -> 1024)\n",
    "            nn.ReLU(),  # ReLU activation\n",
    "            nn.Dropout(0.5),  # Dropout layer (p=0.5)\n",
    "            nn.Linear(1024, n_classes)  # Linear layer (1024 -> n_classes)\n",
    "        )\n",
    "        return classifier\n",
    "\n",
    "linear_classifier = construct_classifier(latent_dim, n_classes).to(device)  # Initialize the linear classifier\n",
    "print(linear_classifier)\n",
    "\n"
   ],
   "id": "7386ef7ca0e8a554",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the linear classifier\n",
    "lin_optim = torch.optim.Adam(linear_classifier.parameters(), lr=0.0001) # Define the optimizer\n",
    "scheduler = StepLR(lin_optim, step_size=15, gamma=0.5)  # Define the learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()  # Define the loss function (Cross-Entropy loss)\n",
    "epochs = 20\n",
    "net.eval()  # Set the convolutional part to evaluation mode\n",
    "\n",
    "#Initialization\n",
    "loss_list = []\n",
    "epoch_loss = []\n",
    "test_acc_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "prog_bar = tqdm( trainloader, total=len(trainloader))\n",
    "for epoch in range(epochs):\n",
    "    for i, (sample, _) in enumerate(prog_bar):\n",
    "            linear_classifier.train() # Set the linear classifier to training mode\n",
    "            lin_optim.zero_grad()\n",
    "            images = sample['image'].to(device)\n",
    "            labels = sample['label'].to(device)\n",
    "            \n",
    "            # Forward + Backward + Optimize  \n",
    "            z = net.conv(images)    # Forward pass through the convolutional layers\n",
    "            z = torch.flatten(z, 1) # Flatten the output from the convolutional layers\n",
    "            outputs = linear_classifier(z)     # Forward pass through the linear classifier\n",
    "            loss = criterion(outputs, labels)  # Calculate the loss\n",
    "            loss.backward()\n",
    "            lin_optim.step()\n",
    "            loss_list.append(loss.item())\n",
    "    epoch_loss.append(np.mean(loss_list))\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss[-1]:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluate the linear classifier\n",
    "    linear_classifier.eval()\n",
    "    y_true, y_pred, test_loss, test_acc = evaluate_classifier(linear_classifier, testloader)\n",
    "    \n",
    "    test_acc_list.append(test_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    print(f\"epoch: {epoch+1}, Validation Accuracy: {test_acc*100}%\", f\"Validation Loss: {test_loss}\")\n",
    "    scheduler.step()  # Update the learning rate scheduler on validation loss\n",
    "    \n",
    "    #Save the best model\n",
    "    if epoch == 0:\n",
    "        best_loss = test_loss\n",
    "    else:\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            torch.save(linear_classifier.state_dict(), \"best_linear_classifier.pth\")"
   ],
   "id": "72dea2e397613ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Load the best model\n",
    "linear_classifier = construct_classifier(latent_dim, n_classes).to(device)\n",
    "linear_classifier.load_state_dict(torch.load('best_linear_classifier.pth'))"
   ],
   "id": "13432fe46c5cac3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the linear classifier\n",
    "y_true, y_pred, test_loss, test_acc = evaluate_classifier(linear_classifier, testloader)"
   ],
   "id": "319ed7942842a606",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
