{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supervised Learning part of the project ",
   "id": "2ba68892ca8a1a44"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import torch  # Import the PyTorch library\n",
    "\n",
    "device = torch.device(\"mps:0\") if torch.backends.mps.is_available() else torch.device(\"cpu\")    # Check if GPU is available\n",
    "print(\"Device:\", device)    # Print the device\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e7d0be02fdfef5c",
   "metadata": {},
   "source": [
    "# Import the libraries\n",
    "import glob  \n",
    "from PIL import Image \n",
    "import numpy as np  \n",
    "import os  \n",
    "import matplotlib.pyplot as plt  \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils  \n",
    "import pandas as pd\n",
    "import scipy  \n",
    "import seaborn as sns \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e32e5d02242afc8f",
   "metadata": {},
   "source": "Define a path pattern to search for all jpg images \n"
  },
  {
   "cell_type": "code",
   "id": "47fdc7633d25a37f",
   "metadata": {},
   "source": [
    "image_path_pattern = \"/Users/stefanocarotti/Supervised/Project/train_set/*.jpg\"\n",
    "\n",
    "# Find all image file paths matching the pattern\n",
    "image_paths = glob.glob(image_path_pattern)\n",
    "\n",
    "# Print the number of images found\n",
    "print(\"Number of images found:\", len(image_paths))\n",
    "Image.open(image_paths[0])  # Show the first image in the list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Mean and standard deviation of the images\n",
    "The results are:\n",
    "Mean pixel values: [0.63867598 0.54430306 0.44470324]\n",
    "\n",
    "Standard deviation of pixel values: [0.22658289 0.24506914 0.26728659] \n",
    "\n",
    "\n",
    "DO NOT RE RUN THIS CELL SINCE IT TAKES A LOT OF TIME"
   ],
   "id": "3336bd4ec1054a59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize variables to store the sum and sum of squares of pixel values\n",
    "mean_pixels = np.zeros(3)  # Initialize mean of pixel values for each channel\n",
    "std_pixels = np.zeros(3)  # Initialize std of pixel values for each channel\n",
    "\n",
    "# Iterate over all images\n",
    "for image_path in image_paths:\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    #Resize the image to 256x256\n",
    "    image = image.resize((256, 256))\n",
    "    \n",
    "    # Convert the image to a NumPy array for each channel\n",
    "    \n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Compute the mean of pixel values for each channel\n",
    "    \n",
    "    mean_pixels += np.mean(image_np, axis=(0, 1))\n",
    "    \n",
    "    # Compute the std of pixel values\n",
    "    std_pixels += np.std(image_np, axis=(0, 1))\n",
    "    \n",
    "# Compute the mean and standard deviation\n",
    "num_images = len(image_paths)  # Get the total number of images\n",
    "mean_pixels = mean_pixels / (num_images)  # Compute the mean pixel values\n",
    "std_pixels = std_pixels / (num_images)  # Compute the standard deviation of pixel values\n",
    "\n",
    "# Print the mean and standard deviation\n",
    "print(\"Mean pixel values:\", mean_pixels)\n",
    "print(\"Standard deviation of pixel values:\", std_pixels)\n",
    "\n",
    "#scale mean and std to 0-1\n",
    "mean_pixels = mean_pixels / 255\n",
    "std_pixels = std_pixels / 255\n",
    "\n",
    "# Print the scaled mean and standard deviation\n",
    "print(\"Mean pixel values:\", mean_pixels)\n",
    "print(\"Standard deviation of pixel values:\", std_pixels)\n",
    "\n"
   ],
   "id": "5d709451566308de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50bcf126bf40ef41",
   "metadata": {},
   "source": [
    "# Check if all images are RGB\n",
    "Since All images are RGB there is no need to convert them\n",
    "\n",
    "DO NOT RE RUN THIS CELL SINCE IT TAKES A LOT OF TIME"
   ]
  },
  {
   "cell_type": "code",
   "id": "4661d629391e4cb4",
   "metadata": {},
   "source": [
    "\n",
    "rgb_images = 0  # Initialize an empty list to store RGB images\n",
    "for image_path in image_paths:\n",
    "  # Open the image \n",
    "  image = Image.open(image_path)\n",
    "\n",
    "  # Get the number of color channels in the image (e.g., RGB has 3 channels)\n",
    "  num_channels = len(image.getbands())\n",
    "\n",
    "  # Check if the image has a different number of channels than expected (likely grayscale or unsupported format)\n",
    "  if num_channels != 3:\n",
    "    rgb_images += 1  # Increment the count of non-RGB images\n",
    "\n",
    "# Print the number of non-RGB images found\n",
    "print(\"Number of non-RGB images found:\", rgb_images)\n",
    "      "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a7d06373287d42",
   "metadata": {},
   "source": [
    "# Define a custom dataset class\n",
    "Then create dataloader for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "id": "7547250ec8b1187d",
   "metadata": {},
   "source": [
    "class FoodDataset(Dataset): \n",
    "      \"\"\"food dataset.\n",
    "\n",
    "      This class loads and preprocesses a dataset of food images with corresponding labels.\n",
    "      \"\"\"\n",
    "\n",
    "      def __init__(self, root_dir, filelist , transform, split, exclude_labels=None):            \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory containing the images.\n",
    "            filelist(string): csv file with informations\n",
    "            transform (callable, optional): Transformation to be applied to the images.\n",
    "            split (string): Split type (\"train\", \"val\").\n",
    "            exclude_labels(int): labels to exclude from the created dataset\n",
    "        \"\"\"\n",
    "        self.split=split\n",
    "        self.root_dir = root_dir  # Set the root directory for the dataset\n",
    "        self.data =  pd.read_csv(filelist, sep=\",\")  # Load the dataset         \n",
    "        \n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Exclude labels if specified\n",
    "        if exclude_labels is not None:\n",
    "            self.data = self.data[~self.data.iloc[:,1].isin(exclude_labels)]\n",
    "            \n",
    "        \n",
    "        total_data_len = int(len(self.data))\n",
    "        idx = np.arange(total_data_len)\n",
    "        np.random.seed(41)\n",
    "        np.random.shuffle(idx)\n",
    "        print(f\"Shuffled indices (first 5): {idx[:5]}\")  # Print first 5 shuffled indices\n",
    "\n",
    "        # Select data based on split\n",
    "        if split == \"train\":\n",
    "            self.data = self.data.iloc[idx[:int(total_data_len * 0.8)]] # Use 80% of the data for training\n",
    "        elif split == \"val\":\n",
    "            self.data = self.data.iloc[idx[int(total_data_len * 0.8):]] # Use 20% of the data for validation\n",
    "        else:\n",
    "            self.data = self.data   # Use all data for testing (only for code clarity)\n",
    "        \n",
    "\n",
    "\n",
    "      def __len__(self):    \n",
    "        \"\"\"\n",
    "        Returns the length of the dataset (number of samples).\n",
    "\n",
    "        This method overrides the default behavior of `len` for the dataset object.\n",
    "        It simply returns the length of the internal `data` list, which represents\n",
    "        the preprocessed data after loading and filtering.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample (image and corresponding label) at a given index.\n",
    "\n",
    "        This method overrides the default behavior of indexing for the dataset object.\n",
    "        It takes an index `idx` and performs the following:\n",
    "            1. Accesses the image name and label at the specified index from `self.data`.\n",
    "            2. Opens the image using `Image.open` with the full path constructed by\n",
    "               combining `self.root_dir` and `img_name`.\n",
    "            3. Applies the defined transformation (`self.transform`) to the image.\n",
    "          \n",
    "            5. Creates a dictionary `sample` containing the preprocessed image (`image`)\n",
    "               and the label.\n",
    "            6. Returns the constructed `sample` dictionary.\n",
    "        \"\"\"\n",
    "        img_name, label = self.data.iloc[idx] \n",
    "        image = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample , img_name"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ab60ec2a5da2038",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Define data transformations (augmentations for training and normalization)\n",
    "transform_train = transforms.Compose([  # Compose multiple transformations together\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally for training augmentation\n",
    "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
    "    transforms.Normalize(  # Normalize pixel values based on mean and standard deviation of the training dataset\n",
    "\n",
    "        mean=[0.63867598, 0.54430306, 0.44470324],\n",
    "        std=[0.22658289, 0.24506914, 0.26728659]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 (consistent with training)\n",
    "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
    "    transforms.Normalize(  # Normalize pixel values using the same statistics\n",
    "        mean=[0.63867598, 0.54430306, 0.44470324],\n",
    "        std=[0.22658289, 0.24506914, 0.26728659]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Set batch size\n",
    "bs = 64\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "\n",
    "trainset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/train_set\",\"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\" ,transform_train, \"train\")\n",
    "\n",
    "valset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/train_set\",\"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\" ,transform_val, \"val\")\n",
    "\n",
    "testset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/val_set\",\"/Users/stefanocarotti/Supervised/Project/annot/val_info.csv\" ,transform_val, \"test\")\n",
    "\n",
    "\n",
    "\n",
    "# Create data loaders for efficient batch training and evaluation\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Print dataset length (number of samples)\n",
    "print(f\"Number of training samples: {len(trainloader) * bs}\")\n",
    "print(f\"Number of validation samples: {len(valloader)}\")\n",
    "print(f\"Number of test samples: {len(testloader)}\")\n",
    "\n",
    "# visualize one example\n",
    "sample, name = trainset[0]\n",
    "print(sample['image'].shape)\n",
    "plt.imshow(sample['image'].permute(1, 2, 0))\n",
    "#plt.title(name)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"sample_image.png\")\n",
    "print(name, sample['label'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the custom model",
   "id": "ad26085ae677a6c1"
  },
  {
   "cell_type": "code",
   "id": "bcb4471163505c3b",
   "metadata": {},
   "source": [
    "import torch.nn as nn # Import the neural network module from PyTorch\n",
    "import torch.nn.functional as F # Import the functional interface module from PyTorch\n",
    "\n",
    "#Define accuracy function\n",
    "def accuracy(prediction, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((prediction == y).sum() / len(y)).item()\n",
    "\n",
    "\n",
    "class FoodNet(nn.Module):  # Define a custom neural network class FoodNet\n",
    "    def __init__(self):  # Define the class constructor\n",
    "        super(FoodNet, self).__init__()\n",
    "        # Define the layers of the network \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv5 = nn.Conv2d(128, 56, 3)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear( 1400 , 500)\n",
    "        self.norm = nn.BatchNorm1d(500) # Batch Normalization\n",
    "        self.fc2 = nn.Linear(500, 251)\n",
    "        \n",
    "        # Pooling layers\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #Define the Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr= 0.0004 )\n",
    "        \n",
    "        # Define the loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "          \n",
    "        \n",
    "       \n",
    "        \n",
    "    def forward(self, x):  # Define the forward pass of the network\n",
    "        x = self.pool1(F.relu(self.conv1(x)))   # Apply relu and pooling to the output of  conv1\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = self.pool1(F.relu(self.conv3(x)))\n",
    "        x = self.pool1(F.relu(self.conv4(x)))\n",
    "        x = self.pool1(F.relu(self.conv5(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.norm(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, sample):    #Training function\n",
    "        \n",
    "        self.optimizer.zero_grad()  #Reset the gradient\n",
    "        image = sample['image'].to(device) #Pass the image and label to the GPU\n",
    "        label = sample['label'].to(device)\n",
    "        prediction = self.forward(image)\n",
    "        loss = self.criterion(prediction, label)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        acc = accuracy(torch.argmax(prediction, dim=1), label)  # Calculate the accuracy\n",
    "        return loss.item(), acc # Return the loss and accuracy\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d48d610b0771e4b6",
   "metadata": {},
   "source": [
    "from torchsummary import summary\n",
    "#summary of the model\n",
    "model = FoodNet()\n",
    "summary(model, (3, 256, 256))\n",
    "#It must have less then 1M parameters"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the model",
   "id": "b9dcd974dfa3fee1"
  },
  {
   "cell_type": "code",
   "id": "df169fa6a4260b9b",
   "metadata": {},
   "source": [
    "from tqdm.auto import tqdm\n",
    "# Import scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, testloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    #Initialization \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    prog_bar = tqdm( testloader, total=len(testloader)) \n",
    "    for i, (sample, _) in enumerate(prog_bar):  # Iterate over the validation data loader\n",
    "        with torch.no_grad():\n",
    "            image = sample['image'].to(device)\n",
    "            label = sample['label'].to(device)\n",
    "            prediction = model.forward(image)\n",
    "            epoch_loss += model.criterion(prediction, label)\n",
    "            epoch_acc += accuracy(torch.argmax(prediction, dim=1), label)\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(torch.argmax(prediction, dim=1).cpu().numpy())\n",
    "            \n",
    "    epoch_loss /= len(testloader)  # Calculate the average loss for the epoch\n",
    "    epoch_acc /= len(testloader)  # Calculate the average accuracy for the epoch        \n",
    "    return y_true, y_pred, epoch_loss, epoch_acc \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = FoodNet().to(device)  # Create an instance of the FoodNet class\n",
    "num_epochs = 70  # Set the number of epochs\n",
    "scheduler = StepLR(model.optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "# Initialize lists to store the training loss and accuracy\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "#Define patience\n",
    "patience = 6\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    prog_bar = tqdm( trainloader, total=len(trainloader))\n",
    "    for i, (sample, _) in enumerate(prog_bar):  # Iterate over the training data loader\n",
    "        loss, acc = model.training_step(sample)  # Calculate the loss and accuracy for the batch\n",
    "        epoch_loss += loss\n",
    "        epoch_acc += acc\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss}, Accuracy: {acc*100}\")\n",
    "    epoch_loss /= len(trainloader)  # Calculate the average loss for the epoch\n",
    "    epoch_acc /= len(trainloader)  # Calculate the average accuracy for the epoch\n",
    "    train_loss.append(epoch_loss)  # Append the average loss to the list\n",
    "    train_acc.append(epoch_acc)  # Append the average accuracy to the list\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}, Accuracy: {epoch_acc*100}%\")\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_true, y_pred, loss, acc = evaluate(model, valloader) \n",
    "    val_loss.append(loss)  # Append the validation loss to the list\n",
    "    val_acc.append(acc)  # Append the validation accuracy to the list   \n",
    "    \n",
    "    \n",
    "    print(f\"epoch: {epoch+1}, Validation Accuracy: {acc*100}%\", f\"Validation Loss: {loss}\")\n",
    "    scheduler.step()  # Update the learning rate scheduler \n",
    "    \n",
    "    \n",
    "    #Save the best model\n",
    "    if epoch == 0:\n",
    "        best_accuracy = acc\n",
    "    else:\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            torch.save(model.state_dict(), \"best_simple_model_nosched.pth\")\n",
    "    # Early stopping\n",
    "    if epoch > patience:\n",
    "        if val_acc[-1] < val_acc[-2]:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        else:\n",
    "            patience = 6\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ],
   "id": "d9c9ddaea5418a6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ccb65d6b269422a2",
   "metadata": {},
   "source": [
    "#Load the saved model \"name_of_the_model.pth\"\n",
    "model = FoodNet().to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#convert val_loss for plotting\n",
    "for i in range(len(val_loss)):\n",
    "    val_loss[i] = val_loss[i].item()"
   ],
   "id": "c0507f240c9dd883",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the training loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_acc)\n",
    "plt.title(\"Training Accuracy\")\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(val_acc)\n",
    "plt.title(\"Validation Accuracy\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(val_loss)\n",
    "plt.title(\"Validation Loss\")\n"
   ],
   "id": "49aafcc5f9a1d53a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Save the accuracies plot for the report\n",
    "plt.figure()\n",
    "plt.plot(train_acc)\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(\"train_acc_finalmodel.png\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_acc)\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(\"val_acc_simple_finalmodel.png\")"
   ],
   "id": "804fa478a19d835c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##Model evaluation on test set",
   "id": "bab61622a0d8047f"
  },
  {
   "cell_type": "code",
   "id": "fed08c272e00e550",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Compute evaluation metrics on test set\n",
    "y_true, y_pred, loss, acc = evaluate(model, testloader)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {acc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff2cbde9b17898a3",
   "metadata": {},
   "source": [
    "# Plot the confusion matrix\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f123492-1d62-403f-a69c-302aa234148b",
   "metadata": {},
   "source": [
    "#Checking the best and worst predicted classes\n",
    "diag = np.diag(cm)\n",
    "print(\"Max true positive\", np.argsort(diag)[-10:])\n",
    "#print the value of the max true positive\n",
    "print(\"Max true positive\", diag[np.argsort(diag)[-10:]])\n",
    "\n",
    "#print lowest 10 true positive\n",
    "print(\"Lowest 10 true positive\", np.argsort(diag)[:35])\n",
    "#print the value of the lowest true positive\n",
    "print(\"Lowest 10 true positive\", diag[np.argsort(diag)[:35]])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a new trainset without label 116 and 58",
   "id": "53b4b0829b3f126c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Using FoodDataset option \"exclude_labels\" \n",
    "new_trainset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/train_set\",\"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\" ,transform_train, \"train\",exclude_labels =  [58, 116])\n",
    "new_valset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/train_set\",\"/Users/stefanocarotti/Supervised/Project/annot/train_info.csv\" ,transform_val, \"val\",exclude_labels =  [58, 116])\n",
    "new_testset = FoodDataset(\"/Users/stefanocarotti/Supervised/Project/val_set\",\"/Users/stefanocarotti/Supervised/Project/annot/val_info.csv\" ,transform_val, \"test\",exclude_labels =  [58, 116])\n",
    "\n",
    "bs = 64\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(new_trainset, batch_size=bs, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(new_valset, batch_size=1, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(new_testset, batch_size=1, shuffle=False)\n",
    "\n"
   ],
   "id": "bacb606241d83917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Number of training samples:\", len(new_trainset))\n",
    "print(\"Number of validation samples:\", len(new_valset))\n",
    "print(\"Number of test samples:\", len(new_testset))\n",
    "\n",
    "print(\"Number of old training samples:\", len(trainset))\n",
    "print(\"Number of old validation samples:\", len(valset))\n",
    "print(\"Number of old test samples:\", len(testset))\n"
   ],
   "id": "b0e50ee4d164b4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model (Remember to change the last fully connected layer output from 251 to 249)\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "model = FoodNet().to(device)  # Create an instance of the FoodNet class\n",
    "num_epochs = 70  # Set the number of epochs\n",
    "scheduler = StepLR(model.optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "# Initialize lists to store the training loss and accuracy\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "#Define patience\n",
    "patience = 6\n",
    "# Iterate over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    prog_bar = tqdm(trainloader, total=len(trainloader))\n",
    "    for i, (sample, _) in enumerate(prog_bar):  # Iterate over the training data loader\n",
    "        loss, acc = model.training_step(sample)  # Calculate the loss and accuracy for the batch\n",
    "        epoch_loss += loss\n",
    "        epoch_acc += acc\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss}, Accuracy: {acc * 100}\")\n",
    "    epoch_loss /= len(trainloader)  # Calculate the average loss for the epoch\n",
    "    epoch_acc /= len(trainloader)  # Calculate the average accuracy for the epoch\n",
    "    train_loss.append(epoch_loss)  # Append the average loss to the list\n",
    "    train_acc.append(epoch_acc)  # Append the average accuracy to the list\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}, Accuracy: {epoch_acc * 100}%\")\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_true, y_pred, loss, acc = evaluate(model, valloader)  # Evaluate the model on the validation set\n",
    "    val_loss.append(loss)  # Append the validation loss to the list\n",
    "    val_acc.append(acc)  # Append the validation accuracy to the list   \n",
    "\n",
    "    print(f\"epoch: {epoch + 1}, Validation Accuracy: {acc * 100}%\", f\"Validation Loss: {loss}\")\n",
    "    scheduler.step()  # Update the learning rate scheduler \n",
    "    \n",
    "    \n",
    "    #Save the best model\n",
    "    if epoch == 0:\n",
    "        best_accuracy = acc\n",
    "    else:\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            torch.save(model.state_dict(), \"best_model_newset.pth\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epoch > patience:\n",
    "        if val_acc[-1] < val_acc[-2]:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        else:\n",
    "            patience = 6\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ],
   "id": "55709ca7154dc2d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ab444e4597d916dc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
